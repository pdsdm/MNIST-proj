{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVE MNIST \n",
    "\n",
    "The LIVE MNIST project aims to create an interactive and dynamic visualization of the training, validation, and testing process for the well-known MNIST dataset. Users will be able to configure the number of layers and nodes in a Convolutional Neural Network (CNN) and observe a live representation of the model’s structure and learning progress directly on a web interface. Additionally, the project will feature an interactive drawing tool where users can sketch digits in real-time and instantly see the model’s predicted probabilities for each number, making the experience both educational and engaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) MODEL rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.56.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.0-cp313-cp313-macosx_11_0_arm64.whl (8.0 MB)\n",
      "Using cached contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp313-cp313-macosx_10_13_universal2.whl (2.7 MB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached numpy-2.2.2-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.2 pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the directions of our training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = \"dataset/train-images.idx3-ubyte\"\n",
    "train_y = \"dataset/train-labels.idx1-ubyte\"\n",
    "test_x = \"dataset/t10k-images.idx3-ubyte\"\n",
    "test_y = \"dataset/t10k-labels.idx1-ubyte\"\n",
    "\n",
    "train_csv = \"./csv_files/train.csv\"\n",
    "test_csv = \"./csv_files/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the ubyte into csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert (imgs, labels, outline, n):\n",
    "    imgf = open(imgs, 'rb') #this function opens the ubyte file.\n",
    "    labelf = open(labels, 'rb')\n",
    "    csvf = open(outline, 'w')\n",
    "\n",
    "    imgf.read(16) #Jumping few bytes due to metadata\n",
    "    labelf.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(labelf.read(1))] #The reason is 1 is because you want to read just 1 byte. When readed, it automatically jumps to next byte.\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(imgf.read(1))) #When appending single num, we added to the list we are in.\n",
    "        images.append(image)  #Finally adding the existing list to another one.\n",
    "    \n",
    "    for image in images:\n",
    "        csvf.write(\",\".join(str(plx) for plx in image)+ \"\\n\") #The conversion into csv file.\n",
    "\n",
    "    imgf.close()\n",
    "    labelf.close()\n",
    "    csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(train_x, train_y, train_csv, 60000) #generating the files\n",
    "convert(test_x, test_y, test_csv, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "train_file = open(train_csv, 'r')  \n",
    "train_list = train_file.readlines()\n",
    "train_file.close()\n",
    "print(len(train_list))\n",
    "num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,43,105,255,253,253,253,253,253,174,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,139,224,226,252,253,252,252,252,252,252,252,158,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,178,252,252,252,252,253,252,252,252,252,252,252,252,59,0,0,0,0,0,0,0,0,0,0,0,0,0,0,109,252,252,230,132,133,132,132,189,252,252,252,252,59,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,29,29,24,0,0,0,0,14,226,252,252,172,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,85,243,252,252,144,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,88,189,252,252,252,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,91,212,247,252,252,252,204,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,125,193,193,193,253,252,252,252,238,102,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,222,252,252,252,252,253,252,252,252,177,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,223,253,253,253,253,255,253,253,253,253,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,123,52,44,44,44,44,143,252,252,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,252,252,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,86,252,252,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,75,9,0,0,0,0,0,0,98,242,252,252,74,0,0,0,0,0,0,0,0,0,0,0,0,0,61,183,252,29,0,0,0,0,18,92,239,252,252,243,65,0,0,0,0,0,0,0,0,0,0,0,0,0,208,252,252,147,134,134,134,134,203,253,252,252,188,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,208,252,252,252,252,252,252,252,252,253,230,153,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,49,157,252,252,252,252,252,217,207,146,45,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,103,235,252,172,103,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Representations:\n",
    "    def rep_imag(list = train_list, num=0):\n",
    "        values = list[num].split(\",\")\n",
    "        images_array = np.asarray(values[1:], dtype=float).reshape((28,28))\n",
    "        plt.imshow(images_array, cmap = \"Grays\", interpolation = \"None\")\n",
    "        plt.grid(True, \"major\")\n",
    "\n",
    "    def rep_matrix (list = train_list, num=0):\n",
    "        values = list[num].split(\",\")\n",
    "        images_array = np.asarray(values[1:], dtype=float).reshape((28,28))\n",
    "        image_matrix = images_array.astype(int)\n",
    "        print(pd.DataFrame(image_matrix).to_string(index=False, header=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Representations.rep_imag(train_list, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0  38  43 105 255 253 253 253 253 253 174   6  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0  43 139 224 226 252 253 252 252 252 252 252 252 158 14 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0 178 252 252 252 252 253 252 252 252 252 252 252 252 59 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0 109 252 252 230 132 133 132 132 189 252 252 252 252 59 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   4  29  29  24   0   0   0   0  14 226 252 252 172  7 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0  85 243 252 252 144  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0  88 189 252 252 252  14  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0  91 212 247 252 252 252 204   9  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0  32 125 193 193 193 253 252 252 252 238 102  28   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0  45 222 252 252 252 252 253 252 252 252 177   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0  45 223 253 253 253 253 255 253 253 253 253  74   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0  31 123  52  44  44  44  44 143 252 252  74   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0  15 252 252  74   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0  86 252 252  74   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   5  75   9   0   0   0   0   0   0  98 242 252 252  74   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0  61 183 252  29   0   0   0   0  18  92 239 252 252 243  65   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0 208 252 252 147 134 134 134 134 203 253 252 252 188  83   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0 208 252 252 252 252 252 252 252 252 253 230 153   8   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0  49 157 252 252 252 252 252 217 207 146  45   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   7 103 235 252 172 103  24   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n",
      "0 0 0 0 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "Representations.rep_matrix(train_list, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "test_file = open(test_csv, 'r')\n",
    "test_list = test_file.readlines()\n",
    "test_file.close()\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, sizes, epochs, lr):\n",
    "        self.sizes = sizes  # Tamaños de las capas\n",
    "        self.epochs = epochs  # Número de épocas\n",
    "        self.lr = lr  # Tasa de aprendizaje\n",
    "\n",
    "        input_layer = sizes[0]\n",
    "        hidden_1 = sizes[1]\n",
    "        hidden_2 = sizes[2]\n",
    "        output_layer = sizes[3]\n",
    "\n",
    "        self.params = {\n",
    "            'W1': np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W2': np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W3': np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        sig = 1 / (1 + np.exp(-x))\n",
    "        if derivative:\n",
    "            return sig * (1 - sig)\n",
    "        return sig\n",
    "    \n",
    "    def softmax(self, x, derivative=False):\n",
    "        exps = np.exp(x - np.max(x))  # Evitar overflow\n",
    "        softmax_vals = exps / np.sum(exps, axis=0)\n",
    "        if derivative:\n",
    "            return softmax_vals * (1 - softmax_vals)\n",
    "        return softmax_vals\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train\n",
    "\n",
    "        params['Z1'] = np.dot(params['W1'], params['A0'])\n",
    "        params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "        params['Z2'] = np.dot(params['W2'], params['A1'])\n",
    "        params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "        params['Z3'] = np.dot(params['W3'], params['A2'])\n",
    "        params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "        return params['A3']\n",
    "    \n",
    "    def backward_pass(self, y_train, output):\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "        change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "        error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "        change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "        change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return change_w\n",
    "    \n",
    "    def update_weights(self, change_w):\n",
    "        for key, val in change_w.items():\n",
    "            if self.params[key].shape == val.shape:\n",
    "                self.params[key] -= self.lr * val\n",
    "\n",
    "    def compute_accuracy(self, test_list):\n",
    "        predictions = []\n",
    "        for x in test_list:\n",
    "            values = x.split(',')\n",
    "            inputs = (np.asarray(values[1:], dtype=np.float32) / 255.0 * 0.99) + 0.01\n",
    "            targets = np.zeros(10) + 0.01\n",
    "            targets[int(values[0])] = 0.99\n",
    "            output = self.forward_pass(inputs)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(targets))\n",
    "\n",
    "        return np.mean(predictions)\n",
    "\n",
    "    def train(self, train_list, test_list):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for iter in range(self.epochs):\n",
    "            for x in train_list:\n",
    "                values = x.split(',')\n",
    "                inputs = (np.asarray(values[1:], dtype=np.float32) / 255.0 * 0.99) + 0.01\n",
    "                targets = np.zeros(10) + 0.01\n",
    "                targets[int(values[0])] = 0.99\n",
    "                output = self.forward_pass(inputs)\n",
    "                change_w = self.backward_pass(targets, output)\n",
    "                self.update_weights(change_w)\n",
    "\n",
    "            accuracy = self.compute_accuracy(test_list)\n",
    "            print(f'Epoch: {iter+1}, Time Spent: {time.time()-start_time:.02f}s, Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 10.84s, Accuracy: 59.50%\n"
     ]
    }
   ],
   "source": [
    "dnn = CNN(sizes = [784, 128, 64, 10], epochs = 10, lr = 0.03)\n",
    "dnn.train(train_list, test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achived an accuraccy of 92.41% which is quite fine but, we could improve this by inserting a decaying learning rate. At the star, this will make big changes on the weights and each epoch will have a decrese on the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_decay:\n",
    "    def __init__(self, sizes, epochs, lr, decay=0.0):\n",
    "        self.sizes = sizes \n",
    "        self.epochs = epochs  \n",
    "        self.lr = lr \n",
    "        self.decay = decay \n",
    "\n",
    "        input_layer = sizes[0]\n",
    "        hidden_1 = sizes[1]\n",
    "        hidden_2 = sizes[2]\n",
    "        output_layer = sizes[3]\n",
    "\n",
    "        self.params = {\n",
    "            'W1': np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W2': np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W3': np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        sig = 1 / (1 + np.exp(-x))\n",
    "        if derivative:\n",
    "            return sig * (1 - sig)\n",
    "        return sig\n",
    "    \n",
    "    def softmax(self, x, derivative=False):\n",
    "        exps = np.exp(x - np.max(x))  \n",
    "        softmax_vals = exps / np.sum(exps, axis=0)\n",
    "        if derivative:\n",
    "            return softmax_vals * (1 - softmax_vals)\n",
    "        return softmax_vals\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train\n",
    "\n",
    "        params['Z1'] = np.dot(params['W1'], params['A0'])\n",
    "        params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "        params['Z2'] = np.dot(params['W2'], params['A1'])\n",
    "        params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "        params['Z3'] = np.dot(params['W3'], params['A2'])\n",
    "        params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "        return params['A3']\n",
    "    \n",
    "    def backward_pass(self, y_train, output):\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "        change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "        error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "        change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "        change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return change_w\n",
    "    \n",
    "    def update_weights(self, change_w):\n",
    "        for key, val in change_w.items():\n",
    "            if self.params[key].shape == val.shape:\n",
    "                self.params[key] -= self.lr * val\n",
    "\n",
    "    def compute_accuracy(self, list=train_list):\n",
    "        predictions = []\n",
    "        for x in list:\n",
    "            values = x.split(',')\n",
    "            inputs = (np.asarray(values[1:], dtype=np.float32) / 255.0 * 0.99) + 0.01\n",
    "            targets = np.zeros(10) + 0.01\n",
    "            targets[int(values[0])] = 0.99\n",
    "            output = self.forward_pass(inputs)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(targets))\n",
    "\n",
    "        return np.mean(predictions)\n",
    "\n",
    "    def train(self, train_list, test_list):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for iter in range(self.epochs):\n",
    "            for x in train_list:\n",
    "                values = x.split(',')\n",
    "                inputs = (np.asarray(values[1:], dtype=np.float32) / 255.0 * 0.99) + 0.01\n",
    "                targets = np.zeros(10) + 0.01\n",
    "                targets[int(values[0])] = 0.99\n",
    "                output = self.forward_pass(inputs)\n",
    "                change_w = self.backward_pass(targets, output)\n",
    "                self.update_weights(change_w)\n",
    "            \n",
    "            self.lr *= (1. / (1. + self.decay * iter))\n",
    "            \n",
    "            accuracy = self.compute_accuracy(test_list)\n",
    "            print(f'Epoch: {iter+1}, Time Spent: {time.time()-start_time:.02f}s, Accuracy: {accuracy*100:.2f}%, Learning Rate: {self.lr:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn2 = CNN_decay(sizes = [784, 128, 64, 10], epochs = 10, lr = 0.9, decay = 0.06)\n",
    "dnn2.train(train_list, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn3 = CNN_decay(sizes = [784, 128, 64, 10], epochs = 10, lr = 2, decay = 0.1)\n",
    "dnn3.train(train_list, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwarding_output(input_data=None, num=None, list = train_list ,neural=dnn3):\n",
    "    \n",
    "    actual_num = None \n",
    "    if num is not None:\n",
    "        values = list[num].split(',')  \n",
    "        inputs = (np.asarray(values[1:], dtype=np.float32) / 255.0 * 0.99) + 0.01 \n",
    "        actual_num = int(float(values[0]))  \n",
    "    elif input_data is not None:\n",
    "        inputs = (np.asarray(input_data, dtype=np.float32) / 255.0 * 0.99) + 0.01  \n",
    "    else:\n",
    "        return None, None\n",
    "    result = neural.forward_pass(inputs)\n",
    "    np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "    predicted_label = int(np.argmax(result)) \n",
    "    return actual_num, predicted_label \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 9944\n",
    "lista = test_list\n",
    "print(forwarding_output(lista, num))\n",
    "Representations.rep_imag(lista, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dnn3.compute_accuracy(train_list))\n",
    "print(dnn3.compute_accuracy(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vs_pred = []\n",
    "lista=test_list\n",
    "j=0\n",
    "\n",
    "for i in lista:\n",
    "    actual, predicted = forwarding_output(None, j, lista)\n",
    "    if actual is not predicted:\n",
    "        print(actual - predicted)\n",
    "        res_vs_pred.append(j)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vs_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
